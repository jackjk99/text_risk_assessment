import streamlit as st
from openai import OpenAI
import pandas as pd
import json
import os
import base64
import io
from datetime import datetime
from dotenv import load_dotenv
import locale
import zipfile
import glob

# í•œêµ­ ë¡œì¼€ì¼ ì„¤ì • (ì„ íƒì‚¬í•­)
try:
    locale.setlocale(locale.LC_TIME, 'ko_KR.UTF-8')  
except:
    pass  # ë¡œì¼€ì¼ ì„¤ì • ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ì°¸ì¡° íŒŒì¼ì´ ì €ì¥ëœ ê¸°ë³¸ í´ë” ê²½ë¡œ
REFERENCE_FILES_FOLDER = "reference_files"
# ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ëª…
DEFAULT_REFERENCE_FILE = "ì°¸ì¡°-SKONS-accessìœ„í—˜ì„±í‰ê°€ì–‘ì‹.xlsx"

# OpenAI API í‚¤ ì½ê¸° í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©)
def load_openai_api_key() -> str:
    """í™˜ê²½ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤."""
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    return api_key

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©)
try:
    api_key = load_openai_api_key()
    client = OpenAI(api_key=api_key)
except Exception as e:
    st.error(str(e))
    client = None

def load_file_content(file_path: str) -> str:
    """
    íŒŒì¼ ê²½ë¡œì—ì„œ íŒŒì¼ì„ ì½ì–´ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    """
    try:
        file_extension = os.path.splitext(file_path)[1].lower()
        
        if file_extension == '.xlsx':
            # Excel íŒŒì¼ ì²˜ë¦¬
            df = pd.read_excel(file_path)
            if df.empty:
                return None
            return df.to_string(index=False)
                
        elif file_extension == '.csv':
            # CSV íŒŒì¼ ì²˜ë¦¬
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                if df.empty:
                    return None
                return df.to_string(index=False)
            except UnicodeDecodeError:
                df = pd.read_csv(file_path, encoding='cp949')
                if df.empty:
                    return None
                return df.to_string(index=False)
                
        elif file_extension == '.txt':
            # í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if not content.strip():
                        return None
                    return content
            except UnicodeDecodeError:
                with open(file_path, 'r', encoding='cp949') as f:
                    content = f.read()
                    if not content.strip():
                        return None
                    return content
        else:
            return None
            
    except Exception as e:
        st.error(f"íŒŒì¼ '{file_path}' ì½ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def load_default_reference_file() -> dict:
    """
    ê¸°ë³¸ ì§€ì •ëœ ì°¸ì¡° íŒŒì¼ì„ ìë™ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    """
    reference_file = {}
    
    # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
    if not os.path.exists(REFERENCE_FILES_FOLDER):
        os.makedirs(REFERENCE_FILES_FOLDER)
    
    # ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ ê²½ë¡œ
    file_path = os.path.join(REFERENCE_FILES_FOLDER, DEFAULT_REFERENCE_FILE)
    
    if os.path.exists(file_path):
        try:
            content = load_file_content(file_path)
            if content:
                reference_file[DEFAULT_REFERENCE_FILE] = {
                    'content': content,
                    'path': file_path,
                    'size': os.path.getsize(file_path),
                    'modified': datetime.fromtimestamp(os.path.getmtime(file_path)).strftime("%Y-%m-%d %H:%M:%S")
                }
                return reference_file
        except Exception as e:
            st.error(f"ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ '{DEFAULT_REFERENCE_FILE}' ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")
    else:
        st.warning(f"âš ï¸ ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ '{DEFAULT_REFERENCE_FILE}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info(f"ğŸ“ íŒŒì¼ì„ `{REFERENCE_FILES_FOLDER}/` í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    
    return reference_file
    """
    ì§€ì •ëœ í´ë”ì—ì„œ ì°¸ì¡° íŒŒì¼ë“¤ì„ ìë™ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    """
    reference_files = {}
    
    # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
    if not os.path.exists(REFERENCE_FILES_FOLDER):
        os.makedirs(REFERENCE_FILES_FOLDER)
        st.warning(f"âš ï¸ '{REFERENCE_FILES_FOLDER}' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ í´ë”ì— ì°¸ì¡° íŒŒì¼ë“¤ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return reference_files
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ìë“¤
    supported_extensions = ['*.xlsx', '*.csv', '*.txt']
    
    for extension in supported_extensions:
        files = glob.glob(os.path.join(REFERENCE_FILES_FOLDER, extension))
        for file_path in files:
            try:
                file_name = os.path.basename(file_path)
                content = load_file_content(file_path)
                if content:
                    reference_files[file_name] = {
                        'content': content,
                        'path': file_path,
                        'size': os.path.getsize(file_path),
                        'modified': datetime.fromtimestamp(os.path.getmtime(file_path)).strftime("%Y-%m-%d %H:%M:%S")
                    }
            except Exception as e:
                st.warning(f"íŒŒì¼ '{file_name}' ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
    
    return reference_files

def load_reference_files_from_folder() -> dict:
    """
    ì§€ì •ëœ í´ë”ì—ì„œ ì°¸ì¡° íŒŒì¼ë“¤ì„ ìë™ìœ¼ë¡œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜ (ê¸°ë³¸ íŒŒì¼ ìš°ì„ )
    """
    reference_files = {}
    
    # ë¨¼ì € ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ì„ ë¡œë“œ
    default_file = load_default_reference_file()
    if default_file:
        reference_files.update(default_file)
        return reference_files  # ê¸°ë³¸ íŒŒì¼ë§Œ ì‚¬ìš©
    
    # ê¸°ë³¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ í´ë”ì˜ ë‹¤ë¥¸ íŒŒì¼ë“¤ì„ ìŠ¤ìº”
    if not os.path.exists(REFERENCE_FILES_FOLDER):
        os.makedirs(REFERENCE_FILES_FOLDER)
        st.warning(f"âš ï¸ '{REFERENCE_FILES_FOLDER}' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ '{DEFAULT_REFERENCE_FILE}'ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        return reference_files
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ìë“¤
    supported_extensions = ['*.xlsx', '*.csv', '*.txt']
    
    for extension in supported_extensions:
        files = glob.glob(os.path.join(REFERENCE_FILES_FOLDER, extension))
        for file_path in files:
            try:
                file_name = os.path.basename(file_path)
                content = load_file_content(file_path)
                if content:
                    reference_files[file_name] = {
                        'content': content,
                        'path': file_path,
                        'size': os.path.getsize(file_path),
                        'modified': datetime.fromtimestamp(os.path.getmtime(file_path)).strftime("%Y-%m-%d %H:%M:%S")
                    }
            except Exception as e:
                st.warning(f"íŒŒì¼ '{file_name}' ë¡œë”© ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue
    
    return reference_files

def parse_analysis_sections(analysis_text: str) -> dict:
    """
    GPT ë¶„ì„ ê²°ê³¼ë¥¼ ì„¹ì…˜ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ìˆ˜ì •)
    """
    sections = {
        "work_analysis": "",           # ì‘ì—… ë‚´ìš© ë¶„ì„
        "risk_table": "",             # ìœ„í—˜ì„± í‰ê°€ í‘œ
        "additional_safety": "",      # ì¶”ê°€ ì•ˆì „ ì¡°ì¹˜
        "safety_checklist": ""        # ì‘ì—… ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
    }
    
    lines = analysis_text.split('\n')
    current_section = None
    current_content = []
    section_started = False
    
    for line in lines:
        line_stripped = line.strip()

        # ì„¹ì…˜ ì‹œì‘ì„ ê°ì§€
        if "ì‘ì—… ë‚´ìš© ë¶„ì„" in line_stripped:
            if current_section and current_content:
                sections[current_section] = '\n'.join(current_content).strip()
            current_section = "work_analysis"
            current_content = []
            section_started = True
            continue

        elif "ìœ„í—˜ì„± í‰ê°€ í‘œ" in line_stripped or "ìœ„í—˜ìš”ì¸ê³¼ ê°ì†ŒëŒ€ì±…" in line_stripped:
            if current_section and current_content:
                sections[current_section] = '\n'.join(current_content).strip()
            current_section = "risk_table"
            current_content = []
            section_started = True
            continue

        elif "ì¶”ê°€ ì•ˆì „ ì¡°ì¹˜" in line_stripped:
            if current_section and current_content:
                sections[current_section] = '\n'.join(current_content).strip()
            current_section = "additional_safety"
            current_content = []
            section_started = True
            continue

        elif "ì‘ì—… ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸" in line_stripped:
            if current_section and current_content:
                sections[current_section] = '\n'.join(current_content).strip()
            current_section = "safety_checklist"
            current_content = []
            section_started = True
            continue

        # ë³¸ë¬¸ ë‚´ìš© ìˆ˜ì§‘
        if current_section and section_started:
            current_content.append(line)

    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
    if current_section and current_content:
        sections[current_section] = '\n'.join(current_content).strip()

    return sections

def create_section_files(sections: dict, timestamp: str, work_description: str) -> dict:
    """
    ê° ì„¹ì…˜ì„ ê°œë³„ íŒŒì¼ë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ìˆ˜ì •)
    """
    files = {}

    # ì‘ì—… ë‚´ìš© ë¶„ì„
    if sections["work_analysis"]:
        files["work_analysis"] = f"""# ì‘ì—… ë‚´ìš© ë¶„ì„

ì‘ì—… ì„¤ëª…: {work_description}
ìƒì„± ì‹œê°„: {timestamp}

{sections["work_analysis"]}
"""
        
    # ìœ„í—˜ì„± í‰ê°€ í‘œ
    if sections["risk_table"]:
        files["risk_table"] = f"""# ìœ„í—˜ì„± í‰ê°€ í‘œ

ì‘ì—… ì„¤ëª…: {work_description}
ìƒì„± ì‹œê°„: {timestamp}

{sections["risk_table"]}
"""

    # ì¶”ê°€ ì•ˆì „ ì¡°ì¹˜
    if sections["additional_safety"]:
        files["additional_safety"] = f"""# ì¶”ê°€ ì•ˆì „ ì¡°ì¹˜

ì‘ì—… ì„¤ëª…: {work_description}
ìƒì„± ì‹œê°„: {timestamp}

{sections["additional_safety"]}
"""

    # ì‘ì—… ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
    if sections["safety_checklist"]:
        files["safety_checklist"] = f"""# ì‘ì—… ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‘ì—… ì„¤ëª…: {work_description}
ìƒì„± ì‹œê°„: {timestamp}

{sections["safety_checklist"]}
"""

    return files

def parse_risk_table_from_markdown(markdown_text: str) -> pd.DataFrame:
    """
    ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ì—ì„œ ìœ„í—˜ì„± í‰ê°€ í‘œë¥¼ ì¶”ì¶œí•˜ì—¬ DataFrameìœ¼ë¡œ ë³€í™˜
    """
    lines = markdown_text.split('\n')
    risk_data = []
    
    # ìœ„í—˜ì„± í‰ê°€ í‘œ ì„¹ì…˜ ì°¾ê¸°
    in_risk_table = False
    for line in lines:
        line = line.strip()
        
        # í‘œ ì‹œì‘ ê°ì§€
        if "ìœ„í—˜ìš”ì¸ê³¼ ê°ì†ŒëŒ€ì±…" in line or ("ì˜ˆìƒë˜ëŠ” ìœ„í—˜ìš”ì¸" in line and "ê°ì†ŒëŒ€ì±…" in line):
            in_risk_table = True
            continue
        
        # ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ ì‹œ í‘œ ì¢…ë£Œ
        if in_risk_table and (line.startswith("## ") and "ìœ„í—˜" not in line and "í‘œ" not in line):
            break
            
        # í‘œ ë°ì´í„° íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ í‘œ í˜•ì‹)
        if in_risk_table and "|" in line and not line.startswith("|---"):
            parts = [x.strip() for x in line.split('|')]
            parts = [part for part in parts if part]  # ë¹ˆ ë¬¸ìì—´ ì œê±°
            
            # í—¤ë” ê±´ë„ˆë›°ê¸° (ìˆœë²ˆ, ì‘ì—… ë‚´ìš© ë“±ì´ í¬í•¨ëœ í–‰)
            if len(parts) >= 7 and parts[0] not in ["ìˆœë²ˆ", ""]:
                try:
                    # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ìˆ«ìì¸ì§€ í™•ì¸ (ì‹¤ì œ ë°ì´í„° í–‰)
                    int(parts[0])
                    risk_data.append(parts[:8])  # 8ê°œ ì»¬ëŸ¼ê¹Œì§€ë§Œ
                except ValueError:
                    continue
    
    if risk_data:
        columns = ["ìˆœë²ˆ", "ì‘ì—… ë‚´ìš©", "ì‘ì—…ë“±ê¸‰", "ì¬í•´ìœ í˜•", "ì„¸ë¶€ ìœ„í—˜ìš”ì¸", "ìœ„í—˜ë“±ê¸‰-ê°œì„ ì „", "ìœ„í—˜ì„± ê°ì†ŒëŒ€ì±…", "ìœ„í—˜ë“±ê¸‰-ê°œì„ í›„"]
        # ë°ì´í„° ê¸¸ì´ì— ë§ì¶° ì»¬ëŸ¼ ì¡°ì •
        max_cols = max(len(row) for row in risk_data) if risk_data else 8
        if max_cols < 8:
            columns = columns[:max_cols]
        
        # ëª¨ë“  í–‰ì˜ ê¸¸ì´ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶¤
        normalized_data = []
        for row in risk_data:
            if len(row) < len(columns):
                row.extend([''] * (len(columns) - len(row)))
            elif len(row) > len(columns):
                row = row[:len(columns)]
            normalized_data.append(row)
        
        return pd.DataFrame(normalized_data, columns=columns)
    else:
        # ê¸°ë³¸ ë¹ˆ DataFrame ë°˜í™˜
        columns = ["ìˆœë²ˆ", "ì‘ì—… ë‚´ìš©", "ì‘ì—…ë“±ê¸‰", "ì¬í•´ìœ í˜•", "ì„¸ë¶€ ìœ„í—˜ìš”ì¸", "ìœ„í—˜ë“±ê¸‰-ê°œì„ ì „", "ìœ„í—˜ì„± ê°ì†ŒëŒ€ì±…", "ìœ„í—˜ë“±ê¸‰-ê°œì„ í›„"]
        return pd.DataFrame(columns=columns)

def analyze_work_risk(work_description: str, selected_references: list) -> dict:
    """
    ì‘ì—… ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ìœ„í—˜ì„± ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    """
    if client is None:
        raise Exception("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # ì„ íƒëœ ì°¸ì¡° íŒŒì¼ë“¤ì˜ ë‚´ìš© ê²°í•©
    combined_reference_content = ""
    for ref_name in selected_references:
        if ref_name in st.session_state['reference_files']:
            combined_reference_content += f"\n\n=== {ref_name} ===\n"
            combined_reference_content += st.session_state['reference_files'][ref_name]['content']
    
    # ìœ„í—˜ì„± í‰ê°€ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸
    prompt = f"""
ë„ˆëŠ” ì•ˆì „ë³´ê±´ ë‹´ë‹¹ìì•¼. í˜„ì¥ì˜ ì‘ì—…ìì—ê²Œ ì‘ì—…ì „ ìœ„í—˜ì„± í‰ê°€ë¥¼ ê°€ì´ë“œí•˜ëŠ” ì—…ë¬´ë¥¼ ë‹´ë‹¹í•˜ê³  ìˆì–´.

ì²¨ë¶€ì˜ ì°¸ì¡°ìë£ŒëŠ” ê° ì‘ì—…ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìœ í•´, ìœ„í—˜ìš”ì¸ë“¤ê³¼ ê·¸ì— ëŒ€í•œ ê°œì„ ë°©ì•ˆì´ ì •ë¦¬ë˜ì–´ ìˆì–´.

ë‚´ê°€ íŠ¹ì • ì‘ì—…ì— ëŒ€í•´ì„œ ë§í•˜ë©´, ìœ„í—˜ìš”ì¸ì€ ì°¸ì¡°ìë£Œë¥¼ ì°¸ê³ í•´ì„œ ìµœëŒ€í•œ ìì„¸íˆ ë‹µë³€í•´ì¤˜.

**ì‘ì—… ë‚´ìš©**: {work_description}

**ì°¸ì¡°ìë£Œ**:
{combined_reference_content}

**ë‹µë³€ í˜•ì‹**:

## ì‘ì—… ë‚´ìš© ë¶„ì„
[ì‘ì—…ì˜ íŠ¹ì„±, ì£¼ìš” ìœ„í—˜ í¬ì¸íŠ¸, ì‘ì—… í™˜ê²½ ë“±ì„ ë¶„ì„]

## ì˜¤ëŠ˜ ì‘ì—…ì—ì„œ ì˜ˆìƒë˜ëŠ” ìœ„í—˜ìš”ì¸ê³¼ ê°ì†ŒëŒ€ì±…ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. í™•ì¸í•´ì£¼ì„¸ìš”.

| ìˆœë²ˆ | ì‘ì—… ë‚´ìš© | ì‘ì—…ë“±ê¸‰ | ì¬í•´ìœ í˜• | ì„¸ë¶€ ìœ„í—˜ìš”ì¸ | ìœ„í—˜ë“±ê¸‰-ê°œì„ ì „ | ìœ„í—˜ì„± ê°ì†ŒëŒ€ì±… | ìœ„í—˜ë“±ê¸‰-ê°œì„ í›„ |
|------|-----------|----------|----------|---------------|----------------|----------------|----------------|
| 1 | [êµ¬ì²´ì  ì‘ì—…] | [Së“±ê¸‰~C1] | [ì¬í•´ìœ í˜•] | [ì„¸ë¶€ ìœ„í—˜ìš”ì¸] | [C1-C4] | [êµ¬ì²´ì  ëŒ€ì±…] | [C1-C4] |
[ì°¸ì¡°ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ ì‘ì—…ê³¼ ê´€ë ¨ëœ ëª¨ë“  ìœ„í—˜ìš”ì¸ì„ ë‚˜ì—´]

## ì¶”ê°€ ì•ˆì „ ì¡°ì¹˜
[ì‘ì—… íŠ¹ì„±ì— ë§ëŠ” ì¶”ê°€ì ì¸ ì•ˆì „ ì¡°ì¹˜ì‚¬í•­]

## ì‘ì—… ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸
[ì‘ì—… ì‹œì‘ ì „ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  ì‚¬í•­ë“¤]

**ì¤‘ìš”ì‚¬í•­**:
- ì°¸ì¡°ìë£Œì˜ ë‚´ìš©ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ í•´ë‹¹ ì‘ì—…ê³¼ ê´€ë ¨ëœ ëª¨ë“  ìœ„í—˜ìš”ì¸ì„ ì‹ë³„
- "ì‘ì—… ë‚´ìš©"ì€ ì‘ì—…ìê°€ ì…ë ¥í•œ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  í™•ì¸í•œ ë‚´ìš© ì¤‘ ì°¸ì¡°ë¬¸ì„œì— ìˆëŠ” ì‘ì—… ë‚´ìš©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‘ì—… ë‚´ìš©ì„ ë„£ê³  ëª¨ëŠ” ìˆœë²ˆì˜ ìœ„í—˜ì„±ì— ë™ì¼í•˜ê²Œ ë„£ì–´ì¤˜
- ìœ„í—˜ë“±ê¸‰ì€ C1(ë‚®ìŒ), C2(ë³´í†µ), C3(ë†’ìŒ), C4(ë§¤ìš°ë†’ìŒ)ìœ¼ë¡œ í‘œì‹œ
- ì‘ì—…ë“±ê¸‰ì€ S(íŠ¹ë³„ê´€ë¦¬), C4, C3, C2, C1ë¡œ êµ¬ë¶„
- ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ëŒ€ì±… ì œì‹œ
- ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±
"""
    
    # OpenAI API í˜¸ì¶œ
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": prompt
            }
        ],
        max_tokens=3000
    )
    
    # GPTì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê¸°
    analysis_result = response.choices[0].message.content
    
    # ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ íŒŒì‹±
    return {
        "work_description": work_description,
        "full_report": analysis_result,
        "sections": parse_analysis_sections(analysis_result),
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "used_references": selected_references
    }

# Streamlit App UI
st.title("ğŸ› ï¸ ì‘ì—… ìœ„í—˜ì„± í‰ê°€ ê°€ì´ë“œ")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'reference_files' not in st.session_state:
    st.session_state['reference_files'] = {}
if 'reference_loaded' not in st.session_state:
    st.session_state['reference_loaded'] = False
if 'analysis_result' not in st.session_state:
    st.session_state['analysis_result'] = None

# # OpenAI API í‚¤ ìƒíƒœ í™•ì¸
# if client is None:
#     st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
# else:
#     st.success("âœ… OpenAI API ì—°ê²° ì™„ë£Œ")

# 1. ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ ìë™ ë¡œë“œ ì„¹ì…˜
st.header("ğŸ“ ìœ„í—˜ì„±ë¶„ì„ ì°¸ì¡° íŒŒì¼ ê´€ë¦¬")

# ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ ì •ë³´ í‘œì‹œ
st.info(f"ğŸ“‚ ê¸°ë³¸ ì°¸ì¡° íŒŒì¼: `{DEFAULT_REFERENCE_FILE}`")

# ì°¸ì¡° íŒŒì¼ ë¡œë“œ ë²„íŠ¼
col1, col2 = st.columns([3, 1])
with col1:
    st.caption(f"íŒŒì¼ ìœ„ì¹˜: `{REFERENCE_FILES_FOLDER}/{DEFAULT_REFERENCE_FILE}`")
with col2:
    if st.button("ğŸ”„ íŒŒì¼ ìƒˆë¡œê³ ì¹¨", type="secondary"):
        st.session_state['reference_files'] = load_reference_files_from_folder()
        st.session_state['reference_loaded'] = True
        st.rerun()

# ì•± ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ ì°¸ì¡° íŒŒì¼ ë¡œë“œ
if not st.session_state['reference_loaded']:
    with st.spinner("ì°¸ì¡° íŒŒì¼ë“¤ì„ ë¡œë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        st.session_state['reference_files'] = load_reference_files_from_folder()
        st.session_state['reference_loaded'] = True

# ë¡œë“œëœ ì°¸ì¡° íŒŒì¼ ëª©ë¡ í‘œì‹œ
if st.session_state['reference_files']:
    st.success(f"âœ… {len(st.session_state['reference_files'])}ê°œì˜ ì°¸ì¡° íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ì°¸ì¡° íŒŒì¼ ì„ íƒ
    st.subheader("ğŸ“‹ ì‚¬ìš©í•  ì°¸ì¡° íŒŒì¼ ì„ íƒ")
    
    # ëª¨ë“  íŒŒì¼ì„ ê¸°ë³¸ìœ¼ë¡œ ì„ íƒ
    default_selection = list(st.session_state['reference_files'].keys())
    selected_files = st.multiselect(
        "ë¶„ì„ì— ì‚¬ìš©í•  ì°¸ì¡° íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)",
        options=list(st.session_state['reference_files'].keys()),
        default=default_selection,
        help="ì„ íƒëœ íŒŒì¼ë“¤ì˜ ë‚´ìš©ì´ ìœ„í—˜ì„± í‰ê°€ì— ì‚¬ìš©ë©ë‹ˆë‹¤."
    )
    
    # ì„ íƒëœ íŒŒì¼ë“¤ ì •ë³´ í‘œì‹œ
    if selected_files:
        with st.expander("ğŸ“„ ì„ íƒëœ ì°¸ì¡° íŒŒì¼ ì •ë³´"):
            for file_name in selected_files:
                file_info = st.session_state['reference_files'][file_name]
                col1, col2, col3 = st.columns([2, 1, 1])
                with col1:
                    st.write(f"**{file_name}**")
                with col2:
                    st.write(f"í¬ê¸°: {file_info['size']:,} bytes")
                with col3:
                    st.write(f"ìˆ˜ì •: {file_info['modified']}")
                
                # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                # with st.checkbox(f"ğŸ” {file_name} ë¯¸ë¦¬ë³´ê¸° ë³´ê¸°"):
                    # preview_content = file_info['content'][:1000] + "..." if len(file_info['content']) > 1000 else file_info['content']
                    # st.text_area("ë‚´ìš©", preview_content, height=200, disabled=True, key=f"preview_{file_name}")
else:
    st.warning("âš ï¸ ì°¸ì¡° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.markdown(f"""
    **ì°¸ì¡° íŒŒì¼ ì¶”ê°€ ë°©ë²•:**
    1. í”„ë¡œì íŠ¸ í´ë”ì— `{REFERENCE_FILES_FOLDER}` í´ë”ë¥¼ ìƒì„±í•˜ì„¸ìš”
    2. ë‹¤ìŒ í˜•ì‹ì˜ íŒŒì¼ë“¤ì„ `{REFERENCE_FILES_FOLDER}` í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”:
       - Excel íŒŒì¼ (.xlsx)
       - CSV íŒŒì¼ (.csv)  
       - í…ìŠ¤íŠ¸ íŒŒì¼ (.txt)
    3. 'ğŸ”„ íŒŒì¼ ìƒˆë¡œê³ ì¹¨' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
    """)

# 2. ì‘ì—… ë‚´ìš© ì…ë ¥ ì„¹ì…˜
st.header("âœï¸ ì‘ì—… ë‚´ìš© ì…ë ¥")

work_input = st.text_area(
    "ì˜¤ëŠ˜ ìˆ˜í–‰í•  ì‘ì—… ë‚´ìš©ì„ ìì„¸íˆ ì…ë ¥í•´ì£¼ì„¸ìš”",
    placeholder="ì˜ˆì‹œ: ì˜¤ëŠ˜ ì² íƒ‘ì—ì„œ ì•ˆí…Œë‚˜ ì¬ì„¤ì¹˜ ì‘ì—…ì´ ìˆì–´ ìœ„í—˜ì„± í‰ê°€ ì•ˆë‚´í•´ì¤˜.",
    height=100,
    help="ì‘ì—… ì¥ì†Œ, ì‘ì—… ë‚´ìš©, ì‚¬ìš© ì¥ë¹„ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ë©´ ë” ì •í™•í•œ ìœ„í—˜ì„± í‰ê°€ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

# 3. ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
if st.session_state['reference_files'] and work_input.strip():
    if not selected_files:
        st.warning("âš ï¸ ë¶„ì„ì— ì‚¬ìš©í•  ì°¸ì¡° íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    elif st.button("ğŸ” ìœ„í—˜ì„± í‰ê°€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        if client is None:
            st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            try:
                with st.spinner("AIê°€ ì‘ì—… ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìœ„í—˜ì„± í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    result = analyze_work_risk(work_input, selected_files)
                    st.session_state['analysis_result'] = result
                
                st.success("âœ… ìœ„í—˜ì„± í‰ê°€ ë¶„ì„ ì™„ë£Œ!")
                
            except Exception as e:
                st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

elif not st.session_state['reference_files']:
    st.info(f"ğŸ“ ë¨¼ì € ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ '{DEFAULT_REFERENCE_FILE}'ì„ ì¤€ë¹„í•´ì£¼ì„¸ìš”.")
elif not work_input.strip():
    st.info("âœï¸ ì‘ì—… ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# 4. ë¶„ì„ ê²°ê³¼ í‘œì‹œ
if st.session_state['analysis_result']:
    result = st.session_state['analysis_result']
    
    st.markdown("---")
    st.header("ğŸ“Š ìœ„í—˜ì„± í‰ê°€ ê²°ê³¼")
    
    # ì‘ì—… ì •ë³´ í‘œì‹œ
    st.markdown(f"**ì‘ì—… ë‚´ìš©**: {result['work_description']}")
    st.markdown(f"**ì‚¬ìš©ëœ ì°¸ì¡° íŒŒì¼**: {', '.join(result.get('used_references', []))}")
    st.caption(f"ìƒì„± ì‹œê°„: {result['timestamp']}")
    
    # ì„¹ì…˜ë³„ íƒ­ ìƒì„±
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“‹ ì „ì²´ ë³´ê³ ì„œ",
        "ğŸ” ì‘ì—… ë¶„ì„", 
        "âš ï¸ ìœ„í—˜ì„± í‰ê°€í‘œ", 
        "âœ… ì•ˆì „ ì¡°ì¹˜"
    ])
    
    sections = result.get('sections', {})
    section_files = create_section_files(sections, result['timestamp'], result['work_description'])
    
    with tab1:
        st.subheader("ì „ì²´ ìœ„í—˜ì„± í‰ê°€ ë³´ê³ ì„œ")
        st.markdown(result['full_report'])
        
        # ì „ì²´ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
        md_content = f"# ì‘ì—… ìœ„í—˜ì„± í‰ê°€ ë³´ê³ ì„œ\n\n"
        md_content += f"**ì‘ì—… ë‚´ìš©:** {result['work_description']}\n\n"
        md_content += f"**ì‚¬ìš©ëœ ì°¸ì¡° íŒŒì¼:** {', '.join(result.get('used_references', []))}\n\n"
        md_content += f"**ìƒì„± ì‹œê°„:** {result['timestamp']}\n\n"
        md_content += result['full_report']
        
        st.download_button(
            label="ğŸ“„ ì „ì²´ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ (.md)",
            data=md_content.encode('utf-8-sig'),
            file_name=f"ìœ„í—˜ì„±í‰ê°€ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown",
            key="full_report_download"
        )
    
    with tab2:
        st.subheader("ì‘ì—… ë‚´ìš© ë¶„ì„")
        if sections.get("work_analysis"):
            st.markdown(sections["work_analysis"])
            if "work_analysis" in section_files:
                st.download_button(
                    label="ğŸ“¥ ì‘ì—… ë¶„ì„ ë‹¤ìš´ë¡œë“œ (.md)",
                    data=section_files["work_analysis"].encode('utf-8-sig'),
                    file_name=f"ì‘ì—…ë¶„ì„_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    mime="text/markdown",
                    key="work_analysis_download"
                )
        else:
            st.info("ì‘ì—… ë¶„ì„ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab3:
        st.subheader("ìœ„í—˜ì„± í‰ê°€í‘œ")
        if sections.get("risk_table"):
            # st.markdown(sections["risk_table"])
            
            # ìœ„í—˜ì„± í‰ê°€í‘œë¥¼ DataFrameìœ¼ë¡œ ì¶”ì¶œ
            try:
                risk_df = parse_risk_table_from_markdown(result['full_report'])
                if not risk_df.empty:
                    st.markdown("### ğŸ“‹ ìœ„í—˜ì„± í‰ê°€ í‘œ (ë°ì´í„°í”„ë ˆì„)")
                    st.dataframe(
                        risk_df, 
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "ìˆœë²ˆ": st.column_config.NumberColumn("ìˆœë²ˆ", width="small"),
                            "ì‘ì—… ë‚´ìš©": st.column_config.TextColumn("ì‘ì—… ë‚´ìš©", width="medium"),
                            "ì‘ì—…ë“±ê¸‰": st.column_config.TextColumn("ì‘ì—…ë“±ê¸‰", width="small"),
                            "ì¬í•´ìœ í˜•": st.column_config.TextColumn("ì¬í•´ìœ í˜•", width="medium"),
                            "ì„¸ë¶€ ìœ„í—˜ìš”ì¸": st.column_config.TextColumn("ì„¸ë¶€ ìœ„í—˜ìš”ì¸", width="large"),
                            "ìœ„í—˜ë“±ê¸‰-ê°œì„ ì „": st.column_config.TextColumn("ìœ„í—˜ë“±ê¸‰-ê°œì„ ì „", width="small"),
                            "ìœ„í—˜ì„± ê°ì†ŒëŒ€ì±…": st.column_config.TextColumn("ìœ„í—˜ì„± ê°ì†ŒëŒ€ì±…", width="large"),
                            "ìœ„í—˜ë“±ê¸‰-ê°œì„ í›„": st.column_config.TextColumn("ìœ„í—˜ë“±ê¸‰-ê°œì„ í›„", width="small")
                        }
                    )
                    
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤ì„ ë‚˜ë€íˆ ë°°ì¹˜
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        csv = risk_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="ğŸ“¥ ìœ„í—˜ì„± í‰ê°€í‘œ CSV ë‹¤ìš´ë¡œë“œ",
                            data=csv.encode('utf-8-sig'),
                            file_name=f"ìœ„í—˜ì„±í‰ê°€í‘œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            key="risk_table_csv_download"
                        )
                    
                    with col2:
                        # MD ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (í‘œ í˜•íƒœ ìœ ì§€)
                        md_table_content = f"""# ìœ„í—˜ì„± í‰ê°€í‘œ

ì‘ì—… ì„¤ëª…: {result['work_description']}
ìƒì„± ì‹œê°„: {result['timestamp']}

{sections["risk_table"]}
"""
                        st.download_button(
                            label="ğŸ“„ ìœ„í—˜ì„± í‰ê°€í‘œ MD ë‹¤ìš´ë¡œë“œ",
                            data=md_table_content.encode('utf-8-sig'),
                            file_name=f"ìœ„í—˜ì„±í‰ê°€í‘œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown",
                            key="risk_table_md_download"
                        )
                        
                else:
                    st.info("ìœ„í—˜ì„± í‰ê°€í‘œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.warning(f"âš ï¸ ìœ„í—˜ì„± í‰ê°€í‘œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        else:
            st.info("ìœ„í—˜ì„± í‰ê°€í‘œ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")    

    with tab4:
        st.subheader("ì•ˆì „ ì¡°ì¹˜ ì‚¬í•­")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ì¶”ê°€ ì•ˆì „ ì¡°ì¹˜**")
            if sections.get("additional_safety"):
                st.markdown(sections["additional_safety"])
            else:
                st.info("ì¶”ê°€ ì•ˆì „ ì¡°ì¹˜ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            st.markdown("**ì‘ì—… ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸**")
            if sections.get("safety_checklist"):
                st.markdown(sections["safety_checklist"])
            else:
                st.info("ì²´í¬ë¦¬ìŠ¤íŠ¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì „ì²´ ì„¹ì…˜ ZIP íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
    if section_files:
        st.markdown("---")
        st.subheader("ğŸ“¦ ì „ì²´ ê²°ê³¼ í†µí•© ë‹¤ìš´ë¡œë“œ")
        
        # ZIP íŒŒì¼ ìƒì„±
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for file_name, content in section_files.items():
                korean_names = {
                    "work_analysis": "1.ì‘ì—…ë¶„ì„",
                    "risk_table": "2.ìœ„í—˜ì„±í‰ê°€í‘œ",
                    "additional_safety": "3.ì¶”ê°€ì•ˆì „ì¡°ì¹˜",
                    "safety_checklist": "4.ì‘ì—…ì „ì²´í¬ë¦¬ìŠ¤íŠ¸"
                }
                zip_file.writestr(
                    f"{korean_names.get(file_name, file_name)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                    content.encode('utf-8-sig')
                )
            
            # ì „ì²´ ë³´ê³ ì„œë„ í¬í•¨
            full_report_content = f"# ì‘ì—… ìœ„í—˜ì„± í‰ê°€ ë³´ê³ ì„œ\n\n"
            full_report_content += f"**ì‘ì—… ë‚´ìš©:** {result['work_description']}\n\n"
            full_report_content += f"**ì‚¬ìš©ëœ ì°¸ì¡° íŒŒì¼:** {', '.join(result.get('used_references', []))}\n\n"
            full_report_content += f"**ìƒì„± ì‹œê°„:** {result['timestamp']}\n\n"
            full_report_content += result['full_report']
            
            zip_file.writestr(
                f"0.ì „ì²´ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                full_report_content.encode('utf-8-sig')
            )
        
        zip_buffer.seek(0)
        
        st.download_button(
            label="ğŸ“ ì „ì²´ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ",
            data=zip_buffer.getvalue(),
            file_name=f"ìœ„í—˜ì„±í‰ê°€ê²°ê³¼_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
            mime="application/zip",
            key="zip_download"
        )

# ì‚¬ìš©ë²• ì•ˆë‚´
with st.expander("ğŸ“– ì‚¬ìš©ë²• ì•ˆë‚´"):
    st.markdown(f"""
    ### ğŸ”§ ì‚¬ìš© ë°©ë²•
    1. **ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ ì¤€ë¹„**: `{REFERENCE_FILES_FOLDER}/` í´ë”ì— `{DEFAULT_REFERENCE_FILE}` íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.
    2. **ìë™ ë¡œë“œ**: ì•± ì‹œì‘ ì‹œ ê¸°ë³¸ íŒŒì¼ì´ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.
    3. **ì‘ì—… ë‚´ìš© ì…ë ¥**: ìˆ˜í–‰í•  ì‘ì—…ì„ êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”.
    4. **ë¶„ì„ ì‹¤í–‰**: 'ìœ„í—˜ì„± í‰ê°€ ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.
    5. **ê²°ê³¼ í™•ì¸**: ìƒì„±ëœ ìœ„í—˜ì„± í‰ê°€ ë³´ê³ ì„œë¥¼ í™•ì¸í•˜ê³  ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.
    
    ### ğŸ“ ì°¸ì¡° íŒŒì¼ ê´€ë¦¬
    - **ê¸°ë³¸ íŒŒì¼**: `{DEFAULT_REFERENCE_FILE}` (ìë™ ì¸ì‹)
    - **íŒŒì¼ ìœ„ì¹˜**: `{REFERENCE_FILES_FOLDER}/` í´ë”
    - **ìë™ ë¡œë“œ**: ì•± ì‹œì‘ ì‹œ ê¸°ë³¸ íŒŒì¼ì„ ìš°ì„ ì ìœ¼ë¡œ ë¡œë“œ
    - **ë°±ì—… ì˜µì…˜**: ê¸°ë³¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ í´ë” ë‚´ ë‹¤ë¥¸ íŒŒì¼ë“¤ì„ ìŠ¤ìº”
    
    ### ğŸ“‹ ì¶œë ¥ ê²°ê³¼
    - **ì‘ì—… ë‚´ìš© ë¶„ì„**: ì…ë ¥í•œ ì‘ì—…ì˜ íŠ¹ì„±ê³¼ ì£¼ìš” ìœ„í—˜ í¬ì¸íŠ¸ ë¶„ì„
    - **ìœ„í—˜ì„± í‰ê°€í‘œ**: ìˆœë²ˆ, ì‘ì—…ë‚´ìš©, ì¬í•´ìœ í˜•, ìœ„í—˜ìš”ì¸, ê°ì†ŒëŒ€ì±…ì„ í‘œ í˜•íƒœë¡œ ì œê³µ
    - **ì¶”ê°€ ì•ˆì „ ì¡°ì¹˜**: ì‘ì—… íŠ¹ì„±ì— ë§ëŠ” ì¶”ê°€ì ì¸ ì•ˆì „ ì¡°ì¹˜ì‚¬í•­
    - **ì‘ì—… ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸**: ì‘ì—… ì‹œì‘ ì „ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  ì‚¬í•­ë“¤
    
    ### ğŸ’¡ ì‘ì—… ì…ë ¥ ì˜ˆì‹œ
    - "ì˜¤ëŠ˜ ì² íƒ‘ì—ì„œ ì•ˆí…Œë‚˜ ì¬ì„¤ì¹˜ ì‘ì—…ì´ ìˆì–´ ìœ„í—˜ì„± í‰ê°€ ì•ˆë‚´í•´ì¤˜"
    - "ì§€í•˜ ë§¨í™€ì—ì„œ ì¼€ì´ë¸” êµì²´ ì‘ì—…ì„ ì§„í–‰í•  ì˜ˆì •ì…ë‹ˆë‹¤"
    - "ê³ ì•• ì „ì„  ê·¼ì²˜ì—ì„œ ì¥ë¹„ ì„¤ì¹˜ ì‘ì—…ì´ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤"
    
    ### âš ï¸ ì£¼ì˜ì‚¬í•­
    - ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ `{DEFAULT_REFERENCE_FILE}`ì„ `{REFERENCE_FILES_FOLDER}` í´ë”ì— ë¯¸ë¦¬ ì¤€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤.
    - ì‘ì—… ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í• ìˆ˜ë¡ ë” ì •í™•í•œ ìœ„í—˜ì„± í‰ê°€ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - ìƒì„±ëœ ê²°ê³¼ëŠ” ì°¸ì¡°ìš©ì´ë¯€ë¡œ, ì‹¤ì œ í˜„ì¥ì—ì„œëŠ” ì¶”ê°€ì ì¸ ì•ˆì „ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.
    
    ### ğŸ”„ íŒŒì¼ ì—…ë°ì´íŠ¸
    - ì°¸ì¡° íŒŒì¼ì„ ìˆ˜ì •í•œ í›„ 'ğŸ”„ íŒŒì¼ ìƒˆë¡œê³ ì¹¨' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.
    - íŒŒì¼ ë³€ê²½ì‚¬í•­ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°˜ì˜ë©ë‹ˆë‹¤.
    """)

# íŒŒì¼ ì •ë³´ ë° ë²„ì „ ì •ë³´
st.markdown("---")
st.markdown("**Version**: v2.1 (ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ ìë™ ë¡œë“œ)")
st.markdown("**Last Updated**: 2025ë…„ 7ì›”")
st.markdown("**Features**: ê¸°ë³¸ ì°¸ì¡° íŒŒì¼ ìë™ ì¸ì‹ â†’ ì‘ì—… ë‚´ìš© ì…ë ¥ â†’ AI ìœ„í—˜ì„± ë¶„ì„ â†’ ë§ì¶¤í˜• ì•ˆì „ ê°€ì´ë“œ ì œê³µ")
st.markdown(f"**ê¸°ë³¸ ì°¸ì¡° íŒŒì¼**: `{REFERENCE_FILES_FOLDER}/{DEFAULT_REFERENCE_FILE}`")